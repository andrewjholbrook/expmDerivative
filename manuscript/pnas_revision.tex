\documentclass[9pt,twocolumn,twoside]{pnas-new}
% Use the lineno option to display guide line numbers if required.

\templatetype{pnasresearcharticle} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\usepackage{amsthm}
\usepackage{bbm}
\usepackage[capitalize,nameinlink,noabbrev]{cleveref}
\usepackage{color}

\newtheorem{Theorem}{Theorem}
\newtheorem{Proposition}[Theorem]{Proposition}
\newtheorem{Lemma}[Theorem]{Lemma}
\newtheorem{Corollary}[Theorem]{Corollary}
\newtheorem{Example}[Theorem]{Example}
\newtheorem{Definition}[Theorem]{Definition}
\newtheorem{Remark}[Theorem]{Remark}
\newtheorem{Question}[Theorem]{Question}
\newtheorem{Assumption}[Theorem]{Assumption}

\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}
\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand*{\fplus}{\genfrac{}{}{0pt}{}{}{+}}
\newcommand*{\fdots}{\genfrac{}{}{0pt}{}{}{\cdots}}
\newcommand{\mb}{\mathbf}
\newcommand{\mc}{\mathcal}
\newcommand{\dx}{\mbox{d}}


\newcommand{\phylogeny}{{\cal T}}
\newcommand{\tree}{\phylogeny}
\newcommand{\order}[1]{{\cal O}\hspace{-0.2em}\left( #1 \right)}



\newcommand{\bbZ}{{\mathbb Z}}
\newcommand{\bbR}{{\mathbb R}}
\newcommand{\bbN}{{\mathbb N}}
\newcommand{\bbC}{{\mathbb C}}
\newcommand{\bbL}{{\mathbb L}}
\newcommand{\bbP}{{\mathbb P}}
\newcommand{\bbQ}{{\mathbb Q}}
\newcommand{\bbF}{{\mathbb F}}
\newcommand{\bbE}{{\mathbb E}}
\newcommand{\bbM}{{\mathbb M}}
\newcommand{\bbS}{{\mathbb S}}
\newcommand{\bPhi}{\mbox{\boldmath ${\rm \Phi}$}}
\newcommand{\bPsi}{\mbox{\boldmath ${\rm \Psi}$}}
\newcommand{\bphi}{\mbox{\boldmath ${\rm \phi}$}}
\newcommand{\bpsi}{\mbox{\boldmath ${\rm \psi}$}}
\newcommand{\Var}{\textnormal{Var\hspace{0.5mm}}}
\newcommand{\?}{\textbf{?}}
\newcommand{\X}{\textbf{X}}
\newcommand{\x}{\textbf{x}}
\newcommand{\Y}{\textbf{Y}}
\newcommand{\z}{\textbf{z}}
\newcommand{\W}{\textbf{W}}
\newcommand{\w}{\textbf{w}}
\newcommand{\avec}{\textbf{a}}
\newcommand{\s}{\textbf{s}}
\newcommand{\Xbar}{\overline{X}}
\newcommand{\xbar}{\overline{x}}
\newcommand{\Ybar}{\overline{Y}}
\newcommand{\ybar}{\overline{y}}
\newcommand{\MM}{\textnormal{MM}}
\newcommand{\ML}{\textnormal{ML}}
\newcommand{\UMVU}{\textnormal{UMVU}}
\newcommand{\iid}{\textnormal{iid}}
\newcommand{\Poi}{\textnormal{Poi}}
\newcommand{\E}{{\mathbf{ E}}}
\newcommand{\A}{{\mathcal A}}
\newcommand{\supp}{\textnormal{supp}}
\newcommand{\Pfam}{{\mathcal P}}
\newcommand{\Cov}{\textnormal{Cov}}
\newcommand{\U}{{\mathcal U}}
\newcommand{\uvec}{{\mathbf u}}
\newcommand{\diag}{\textnormal{diag}}
\newcommand{\imag}{{\mathbf i}}
\newcommand{\op}{\textnormal{op}}
\newcommand{\as}{\textnormal{a.s.}}

\DeclareMathOperator*{\plim}{\mathit{p}-lim}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}


\newcommand{\bW}{\mbox{\boldmath ${\rm W}$}}
\newcommand{\bU}{\mbox{\boldmath ${\rm U}$}}
\newcommand{\bV}{\mbox{\boldmath ${\rm V}$}}
\newcommand{\bA}{\mbox{\boldmath ${\rm A}$}}
\newcommand{\bC}{\mbox{\boldmath ${\rm C}$}}
\newcommand{\bI}{\mbox{\boldmath ${\rm I}$}}
\newcommand{\bB}{\mbox{\boldmath ${\rm B}$}}
\newcommand{\bF}{\mbox{\boldmath ${\rm F}$}}
\newcommand{\bX}{\mbox{\boldmath ${\rm X}$}}
\newcommand{\bY}{\mbox{\boldmath ${\rm Y}$}}
\newcommand{\bQ}{\mbox{\boldmath ${\rm Q}$}}
\newcommand{\bG}{\mbox{\boldmath ${\rm G}$}}
\newcommand{\bT}{\mbox{\boldmath ${\rm T}$}}
\newcommand{\bS}{\mbox{\boldmath ${\rm S}$}}
\newcommand{\bR}{\mbox{\boldmath ${\rm R}$}}

\newcommand{\bSigma}{\mbox{\boldmath ${\rm \Sigma}$}}
\newcommand{\bbeta}{\mbox{\boldmath ${\rm \beta}$}}


\newcommand{\ba}{\mbox{\boldmath ${\rm a}$}}
\newcommand{\bc}{\mbox{\boldmath ${\rm c}$}}
\newcommand{\bd}{\mbox{\boldmath ${\rm d}$}}
\newcommand{\bs}{\mbox{\boldmath ${\rm s}$}}
\newcommand{\bw}{\mbox{\boldmath ${\rm w}$}}
\newcommand{\bv}{\mbox{\boldmath ${\rm v}$}}
\newcommand{\bu}{\mbox{\boldmath ${\rm u}$}}
\newcommand{\bx}{\mbox{\boldmath ${\rm x}$}}
\newcommand{\by}{\mbox{\boldmath ${\rm y}$}}
\newcommand{\bxi}{\mbox{\boldmath ${\rm \xi}$}}
\newcommand{\bgee}{\mbox{\boldmath ${\rm g}$}}
\newcommand{\bepsilon}{\mbox{\boldmath ${\rm \epsilon}$}}

\newcommand{\bzero}{\mbox{\boldmath $0$}}




\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\GD}[1]{#1}
\newcommand{\GDcomment}[2][purple]{GD: \textcolor{#1}{#2}}


\newcommand{\y}{\mathbf{y}}
\newcommand{\QQ}{\mathbf{Q}}
\newcommand{\LLambda}{\boldsymbol{\Lambda}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\JJ}{\mathbf{J}}
\newcommand{\II}{\mathbf{I}}
\newcommand{\AAA}{\mathbf{A}}

\newcommand{\Zero}{\boldsymbol{0}}
\newcommand{\ttheta}{\boldsymbol{\theta}}
\newcommand{\mom}{\boldsymbol{\xi}}
\newcommand{\ppi}{\boldsymbol{\pi}}
\renewcommand{\P}{\mathbf{P}}
\newcommand{\p}{\mathbf{p}}
\newcommand{\q}{\mathbf{q}}
\newcommand{\B}{\mathbf{B}}
\newcommand{\Z}{\mathbf{E}}
\newcommand{\T}{\mathbf{T}}
\newcommand{\TT}{\mathbf{T}}
\newcommand{\RM}{\mathbf{R}}
\newcommand{\UU}{\mathbf{U}}
\newcommand{\VV}{\mathbf{V}}

\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\NN}{\mathbb{N}}

\newcommand{\alert}[1]{\textcolor{red}{#1}}

%\newcommand{\one}{\mathbbm{1}}
\newcommand{\one}{\mathbf{1}}
\newcommand{\matSpace}{\mathcal{M}}

 \newtheorem{@definition}{\bf Definition}
 \newenvironment{definition}{\begin{@definition}\rm}{\end{@definition}}


 \newtheorem{@remark}{\bf Remark}
 \newenvironment{remark}{\begin{@remark}\rm}{\end{@remark}}

 \newtheorem{@example}{\bf Example}
 \newenvironment{example}{\begin{@example}\rm}{\end{@example}}


% \newtheorem{remark}{\bf Remark}
 \newtheorem{theorem}{\bf Theorem}
 \newtheorem{lemma}{\bf Lemma}
 \newtheorem{fact}{\bf Fact}
 \newtheorem{corollary}{\bf Corollary}
 \newtheorem{axiom}{\bf Axiom}
 \newtheorem{condition}{\bf Condition}
 \newtheorem{property}{\bf Property}
 \newtheorem{proposition}{\bf Proposition}



\allowdisplaybreaks[1]

\graphicspath{{figures/}}


%\input{make-edits}


\title{On the surprising effectiveness of a simple matrix exponential derivative approximation, with application to global SARS-CoV-2}

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[a]{Gustavo Didier}
\author[a]{Nathan E.~Glatt-Holtz} 
\author[b,1]{Andrew J.~Holbrook}
\author[b]{Andrew F.~Magee}
\author[b,c,d]{Marc A.~Suchard}



\affil[a]{Department of Mathematics, Tulane University}
\affil[b]{Department of Biostatistics, University of California, Los Angeles}
 \affil[c]{Department of Biomathematics, University of California, Los Angeles}
 \affil[d]{Department of Human Genetics, University of California, Los Angeles}

% Please give the surname of the lead author for the running footer
\leadauthor{Didier} 

% Please add a significance statement to explain the relevance of your work
\significancestatement{Recent work uses a simplistic approximation to
  the matrix exponential derivative to apply gold-standard models from
  evolutionary biology to a collection of challenging data
  analyses. Whereas one may expect the naive approach to break down
  with increasing model dimensionality, empirical results show no such
  failure.  Here, we (1) develop rigorous error bounds that
  improve---in a certain sense---as model dimension grows and (2)
  demonstrate the scalability of the naive approach to a
  higher-dimensional analysis of the global spread of the virus
  responsible for the COVID-19 pandemic.}

% Please include corresponding author, author contribution and author declaration information
 \authorcontributions{AJH and MAS designed research. GD, NEGH and AJH developed mathematical results. AJH and AFM performed simulations and data analysis.  GD, NEGH and AJH wrote the paper.}
% \authordeclaration{Please declare any competing interests here.}
% \equalauthors{\textsuperscript{1}A.O.(Author One) contributed equally to this work with A.T. (Author Two) (remove if not applicable).}
\correspondingauthor{\textsuperscript{1}To whom correspondence should be addressed. E-mail: aholbroo@g.ucla.edu}

% At least three keywords are required at submission. Please provide three to five keywords, separated by the pipe symbol.
\keywords{Continuous-time Markov chains $|$  Hamiltonian Monte Carlo $|$ Matrix exponential $|$ Molecular epidemiology $|$ Random matrix theory } 

\begin{abstract}
  The continuous-time Markov chain (CTMC) is the mathematical
  workhorse of evolutionary biology.  Learning CTMC model parameters
  using modern, gradient-based methods requires the derivative of the
  matrix exponential evaluated at the CTMC's infinitesimal generator
  (rate) matrix.  Motivated by the derivative's extreme computational
  complexity as a function of state space cardinality, recent work
  demonstrates the surprising effectiveness of a naive, first-order
  approximation for a host of problems in computational biology.  In
  response to this empirical success, we obtain rigorous deterministic and
  probabilistic bounds for the error accrued by the naive
  approximation and establish a ``blessing of dimensionality'' result
  that is universal for a large class of rate matrices with random
  entries.  Finally, we apply the first-order approximation within
  surrogate-trajectory Hamiltonian Monte Carlo for the analysis of the
  early spread of SARS-CoV-2 across 44 geographic regions that
  comprise a state space of unprecedented dimensionality for
  unstructured (flexible) CTMC models within evolutionary biology.
\end{abstract}

\dates{This manuscript was compiled on \today}
\doi{\url{www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX}}

\begin{document}

\maketitle
\thispagestyle{firststyle}
\ifthenelse{\boolean{shortarticle}}{\ifthenelse{\boolean{singlecolumn}}{\abscontentformatted}{\abscontent}}{}

% If your first paragraph (i.e. with the \dropcap) contains a list
% environment (quote, quotation, theorem, definition, enumerate,
% itemize...), the line after the list may have some extra
% indentation. If this is the case, add \parshape=0 to the end of the
% list environment.



\dropcap{P}hylogeographic methods
\cite{lemey2009bayesian, lemey2014unifying, holbrook2021massive,
  holbrook2022viral} model large-scale viral transmission between
human populations as a function of the shared evolutionary history of
the viral population of interest.  Data take the form of dates,
locations and genome sequences associated to individual viral
samples. Spatiotemporal structure interfaces with network structure
given by the phylogeny, or family tree, describing the viruses'
collective history beginning with the most recent common ancestor.
While one cannot directly observe this history, one may statistically
reconstruct the phylogenetic tree by positing that changes in the
viral genome happen randomly at regular intervals, thereby capturing
the intuition that viral samples with more differences between their
(aligned) sequences should find themselves further apart on the family
tree.

The continuous-time Markov chain (CTMC) \cite{norris_1997}
represents the gold-standard mathematical model for such evolution of
characters (e.g., nucleotides) within a fixed span of evolutionary
time. A CTMC defined over a discrete, $d$-element state space consists
of a row vector $\ppi_0$ whose individual components describes the
probability of inhabiting each of the possible states at time $t=0$,
as well as a $d\times d$ infinitesimal generator (or rate) matrix
$\QQ$ with non-negative off-diagonal elements $q_{ij}$, $i\neq j$, and
non-positive diagonal elements $q_{ii}=-\sum_j q_{ij}$. For any lag
$t\geq 0$, the matrix exponential
\cite{moler1978nineteen,moler2003nineteen} provides the Markov chain's
transition probability matrix
\begin{align}
    \P_t := e^{t \QQ} := \sum_{n=0}^\infty \frac{t^n\QQ^n}{n!}  \, ,
\end{align}
which has elements $[\P_t]_{ij}$ that dictate the probability of the
process jumping from state $i$ to state $j$ after time $t$. It is
straightforward to verify that $\P_t$ is a valid transition matrix,
having probability vectors for rows: if $\one$ and $\Zero$ are the
column vectors of ones and zeros, respectively, then $\QQ\one=\Zero$
and, therefore, $\P_t\one=\one$. The law of total probability then
provides the marginal probability of the process at any time
$t \geq 0$ as $\ppi_t=\ppi_0 e^{t\QQ}$.

Whether frequentist \cite{felsenstein1981evolutionary} or Bayesian
\cite{sinsheimer1996bayesian, yang1997bayesian, mau1999bayesian,
  suchard2001bayesian}, likelihood-based approaches to phylogenetic
reconstruction allow phylogenetic tree branch lengths to parameterize
time lags within the CTMC framework. We present the exact statement of
the phylogenetic CTMC paradigm below (see \cref{sec:sars:cov:app}).
Here, we note that the historical importance of tree-reconstruction
from aligned sequences leads to an early emphasis on the
sparse specification of $\QQ$ based on biologically motivated
assumptions
\cite{jukes1969evolution,kimura1980simple,hasegawa1985dating}.
Classical Markov chain Monte Carlo (MCMC) procedures
\cite{metropolis1953equation,hastings1970monte} work well for such
low-dimensional models.  But the phylogenetic CTMC framework has
applications beyond simple nucleotide substitution models. Within,
e.g., Bayesian phylogeography, the work in \cite{lemey2009bayesian}
provides a phylogenetic CTMC model for the spread of avian influenza
across $d=20$ global geographic locations but, for computational
reasons, favors a low-dimensional $\order{d}$ parameterization of
$\QQ$. Similarly, \cite{lemey2014unifying} model the spread of
influenza A H1N1 and H3N2 between as many as $d=26$ geographic regions
but---again for computational reasons---fit the model with
approximation techniques that provide no inferential guarantees.

Recently, \cite{magee2023random} demonstrate the feasibility of
approximate gradient-based methods for both maximum \emph{a
  posteriori} and full Bayesian inference of flexible and
fully-parameterized rate models and apply these methods to a
gold-standard $\order{d^2}$ mixed-effect CTMC model for the spread of
A H3N2 influenza between $d=14$ geographic locations. The usual
CTMC log-likelihood gradient calculations feature the matrix
exponential derivative (see \eqref{eq:sen:eq}, \eqref{eq:var:const:2} below)
\begin{align}
\label{eq:grad:def}
  &\nabla_{\JJ} e^{t \QQ}
    := \lim_{\epsilon \to 0}
    \frac{e^{t (\QQ+ \epsilon \JJ)} - e^{t\QQ} }{\epsilon} \\
  &=  e^{t \QQ} \sum_{n = 0}^\infty \frac{t^{n+1}}{(n+1)!}  
    \left( \sum_{\ell = 0}^n
    (-1)^\ell \binom{n}{\ell} \QQ^\ell \JJ \QQ^{n -\ell}\right)
    \label{eq:grad:series}
\end{align}
computed in the direction $\JJ$ of each of the $d^2$ natural basis
elements $\JJ_{ij}$ spanning the space of real-valued, $d\times d$
matrices ${\mathcal M}(d)={\mathcal M}(d,\bbR)$, thereby requiring at least $\order{d^5}$
floating point operations \cite{najfeld1995derivatives}.

Within the phylogenetic CTMC models of Section \ref{sec:sars:cov:app}, log-likelihood derivative computations that require $\nabla_{\JJ} e^{t \QQ}$ balloon to $\order{KNd^5}$, for $N$ the number of biological specimens observed and $K$ the number of parameters parameterizing $\QQ$.
To address this overwhelming computational cost, \cite{magee2023random} leverage
the simplistic approximation obtained by setting $n=0$ within \eqref{eq:grad:series}:
\begin{align}\label{eq:firstOrder}
	\widetilde{\nabla}_{\JJ} e^{t\QQ} := t e^{t\QQ}\JJ   \, .
\end{align}
\cite{magee2023random} show that this approximation helps reduce total cost to $\order{Kd^2 + Nd^3}$ and use this speedup within
surrogate-trajectory Hamiltonian Monte Carlo (see Supplement) 
to obtain a
34-fold improvement in effective sample size per second (ESS/s) over
random-walk MCMC within their 14 region phylogeographic example.
When trying to explain the remarkable empirical performance of the naive
approximation, the authors derive an error upper
bound (for an arbitrary matrix norm)
\begin{align}\label{eq:initial:bnd}
  \lVert \widetilde{\nabla}_{\JJ}e^{t \QQ}  - \nabla_{\JJ} e^{t \QQ} \rVert
  \leq \frac{ \| \JJ \| \lVert\QQ \rVert }{2} (e^{2t} -2t-1) 
\end{align}
that fails to leverage the specific forms of $\QQ$ and $\JJ$.
Notably, this bound explodes as either $t$ or $\lVert \QQ \rVert$
diverges to $\infty$.  Of course, the latter quantity would be
expected to grow large with dimension $d$ without more careful
structural assumptions, e.g., that $\QQ$ is a rate matrix belonging to
the class
\begin{align}\label{eq:rate:mat}
  \mathcal{R}(d) :=
  \Big\{ \QQ \in {\mathcal M}(d) |
  \QQ_{ij} \geq 0 \text{ for } j \not= i ,\, \sum_{j =1}^d \QQ_{ij} = 0 \Big\} \, .
\end{align}

In the following, we use the finer structural properties of $\QQ$ to
obtain more precise bounds on
\begin{align}\label{eq:true:diff}
  \Z(t) := \nabla_\JJ e^{t \QQ} - t e^{t \QQ} \JJ.
\end{align}
In \cref{thm:ass:error}, we provide an affine (in $t$) correction to the 
approximation \eqref{eq:firstOrder} that yields an exponentially tight 
$t \to \infty$ asymptotic for the error \eqref{eq:true:diff}. Then, in 
\cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.}, we establish
precise probabilistic bounds in the high-dimensional $d \to \infty$
limit for a large class of randomly drawn rate matrices
$\QQ \in \mathcal{R}$.  Here we show, for any $\QQ \in \mathcal{R}$
whose off-diagonal elements are determined by independently and identically distributed (iid) draws from a
positive, sub-exponential distribution $F$, that all of the non-zero
singular values grow as $\sigma_j(\QQ) \sim d$ along with
asymptotically valid almost sure bounds for these rates as
$d \to \infty$. 

In regards to this second result,
\cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.}, note that random rate (or
`Laplacian') matrices have attracted a great deal of attention from the
probability research community, especially in regard to their
high-dimensional properties; see e.g., \cite{takahashi:1969,bai:1999,
  chafai:2010, bordenave:caputo:chafai:2012, chatterjee:hazra:2022,
  nakerst:denisov:haque:2023}. In particular, seminal papers such as
\cite{bryc:dembo:jiang:2006, ding:jiang:2010,
  bordenave:caputo:chafai:2014} establish broad characterizations of
bulk behavior for the Laplacian eigenspectrum.  One contribution of
this paper, of independent interest, is a short and self-contained
construction of useful bounds for the singular values of
$\QQ \in \mathcal{R}$.

In \cref{thm:bride:of:frankinstein} and
\cref{cor:rig:det:rand:wrapup}, we show how \cref{thm:ass:error} and
\cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.} combine to provide a more
refined analysis of $\E$ for suitable randomly generated
$\QQ \in \mathcal{R}(d)$. In \cref{thm:bride:of:frankinstein}, we
establish that particular terms appearing in the bound
\eqref{eq:ass:error} in \cref{thm:ass:error} decay with a rate on the
order of $1/d$ in the operator norm topology for large $d$ for certain
classes of symmetric generators $\QQ$. This class includes the random
elements considered in \cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.}.
Here, although \cref{cor:rig:det:rand:wrapup} applies only for
symmetric matrices composed of sub-exponential draws, we provide
strong supplemental numerical evidence that our bounds remain valid
well beyond this special symmetric, sub-exponential special case; see
\cref{rmk:better:approx} and \cref{fig:app}.

One notable practical implication of \cref{thm:bride:of:frankinstein},
\cref{cor:rig:det:rand:wrapup} and \cref{rmk:better:approx} is the
identification of a further correction to
\eqref{eq:firstOrder}. Crucially this correction has the same
$\order{d^3}$ computational cost as \eqref{eq:firstOrder} while
leading to an asymptotically temporally uniformly accurate
approximation of $\nabla_{\JJ} e^{t \QQ}$.  See
\cref{rmk:better:approx} and \eqref{eq:better:help:on:sale} below.

 \cref{sec:emp} contains simulation studies comparing: accuracy of matrix exponential derivative approximations for different distributional assumptions on the generator matrix; the posterior distributions obtained using surrogate-trajectory Hamiltonian Monte Carlo and traditional Hamiltonian Monte Carlo; and parameter identification under different priors on generator matrix elements.

In \cref{sec:sars:cov:app} we follow these theoretical and empirical investigations
with an application of the naive, first-order gradient approximation
\eqref{eq:firstOrder} to a challenge in phylogeography requiring
Bayesian inference of a rate-matrix of unprecedented dimensionality.
Namely, we apply the approximation to a gold-standard mixed-effects,
phylogenetic CTMC model that uses 1,897 parameters to describe the
spread of SARS-CoV-2 across a $d=44$ dimensional state space
consisting of different global geographic locations.  Such an
application complements the empirical studies of
\cite{magee2023random} in a manner that emphasizes the naive
approximation's potential for impact.





\section{Rigorous Results}
\label{sec:rig:results}

This section lays out our rigorous results \cref{thm:ass:error},
\cref{thm:bride:of:frankinstein},
\cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.} and
\cref{cor:rig:det:rand:wrapup}, the proofs of which appear in the
Supplement.

In what follows we adopt the following notational conventions. For any
${\mathbf A} \in {\mathcal M}(d)$, we list the associated (not
necessarily distinct) eigenvalues of $\mathbf{A}$ in ascending order
according to their real part, namely,
\begin{align}\label{eq:EV:real:ass}
  \Re \lambda_1({\mathbf A}) \leq \cdots \leq \Re \lambda_d({\mathbf A}).
\end{align}
Similarly, the singular values of ${\mathbf A}$ are written in
ascending order
\begin{align}\label{eq:SV:ass}
  \sigma_1({\mathbf A}) \leq \cdots \leq \sigma_d({\mathbf A}).
\end{align}
We let ${\mathcal S}(d) = {\mathcal S}(d,\bbR)$ and ${\mathcal S}(d,\bbC)$ represent the spaces of $d \times d$ symmetric and Hermitian matrices,
respectively.

We make use of multiple matrix norms leading to
materially different bounds as $d \rightarrow \infty$ \cite{trefethen2022numerical}.  Take
\begin{align}\label{eq:frob:norm}
  \|\mathbf{A}\|_{F} := \sqrt{\sum_{i,j =1}^d \mathbf{A}_{ij}^2} =
  \sqrt{\sum_{j =1}^d \sigma_j(\mathbf{A})^2}
\end{align}
for the \emph{Frobenius norm} and
\begin{align}\label{eq:op:norm}
  \|{\mathbf A}\|_{\textnormal{op}} :=  \sqrt{\lambda_d({\mathbf
  A}^*{\mathbf A})} = \sqrt{\lambda_d({\mathbf A}{\mathbf A}^*)}
  = \sigma_d(\mathbf{A})
\end{align}
for the \emph{operator norm} of ${\mathbf A}$.  Finally note that when we
simply write $\| \cdot \|$ the statement then holds for any valid
matrix norm as in our formulation of \cref{thm:ass:error}.

\subsection*{Deterministic bounds on approximation
  error in time}

We begin by deriving a dynamical equation for the error $\Z(t)$, defined in
\eqref{eq:true:diff}. Recall that $\X(t) := e^{t \QQ}$ for any
$\QQ \in \mathcal{M}(d)$ obeys the (matrix-valued) ordinary
differential equation
\begin{align}
   \frac{d\X}{dt} = \QQ \X, \quad \X(0) = \II.
\end{align}
Setting
$\Y^\epsilon = \epsilon^{-1} ( e^{t (\QQ+ \epsilon \JJ)}- e^{t \QQ})$
and taking a limit as $\epsilon \to 0$ we find that
$\Y = \nabla_{\JJ} e^{t \QQ}$ obeys
\begin{align}
  \frac{d \Y}{dt}  = \QQ \Y + \JJ \X = \QQ \Y + \JJ e^{t \QQ},
  \quad \Y(0) = \Zero.
	\label{eq:sen:eq}
\end{align}
Thus, variation of constants yields that, for any $t \geq 0$,
\begin{align}
	\nabla_{\JJ} e^{t \QQ} &= e^{t \QQ} \int_0^t e^{-s\QQ} \JJ e^{s\QQ} ds \label{eq:var:const:1}\\
	&=  e^{t \QQ} \sum_{k,m = 0}^\infty \int_0^t \frac{(-s)^{k} \QQ^k \JJ s^{m}\QQ^m}{k!m!}ds
		\notag\\
	&=  e^{t \QQ} \sum_{n = 0}^\infty \frac{t^{n+1}}{(n+1)!}  
	\left( \sum_{\ell = 0}^n (-1)^\ell \binom{n}{\ell} \QQ^\ell \JJ \QQ^{n -\ell}\right).
	\label{eq:var:const:2}
\end{align}
Taking the first order ($n=0$) approximation in \eqref{eq:var:const:2} produces
\eqref{eq:firstOrder}.  Note that, from \eqref{eq:var:const:1}, this
approximation $\widetilde{\nabla}e^{t\QQ}\JJ$ is evidently exact in the
special case when $\JJ$ and $\QQ$ commute.


Next notice that, if we differentiate $\widetilde{\Y} := t e^{t \QQ} \JJ$ in $t$, we
find that $\widetilde{\Y}$ obeys
\begin{align}\label{eq:sen:eq:apx}
  \frac{d \widetilde{\Y}}{dt} = \QQ \widetilde{\Y} +  e^{t \QQ} \JJ,
  \quad \widetilde{\Y}(0) = \Zero.
\end{align}
Thus, taking the error $\Z(t)$ as in \eqref{eq:true:diff} and
combining \eqref{eq:sen:eq} with \eqref{eq:sen:eq:apx} yields
\begin{align}
\label{eq:Z:dym}
  \frac{d\Z}{dt} = \QQ \Z + \JJ e^{t \QQ} -  e^{t \QQ} \JJ,
  \quad \Z(0) = \Zero.
\end{align}
Hence, again integrating this expression, we find
\begin{align}
  \Z(t) &= e^{t \QQ} \int_0^t (e^{-s \QQ} \JJ e^{s \QQ} - \JJ) ds
 \label{eq:ass:procs:0}\\
	&=  e^{t \QQ} \sum_{n = 1}^\infty \frac{t^{n+1}}{(n+1)!}  
   \left( \sum_{\ell = 0}^n (-1)^\ell
   \binom{n}{\ell} \QQ^\ell \JJ \QQ^{n -\ell}\right)
   \label{eq:ass:procs}
\end{align}
as could also be directly deduced from \eqref{eq:var:const:1},
\eqref{eq:var:const:2}.

Given a rate matrix $\QQ$ in $\mathcal{R}(d)$, recall that
$\Re \lambda_{d-1}(\QQ) \leq \lambda_{d}(\QQ)= 0$ by
the Gershgorin circle theorem \cite[Theorem
6.1.1]{horn:johnson:2012}.  Imposing a further
non-degeneracy assumption (e.g., that $\Re \lambda_{d-1}(\QQ)< 0$) we
therefore have an exponential decay in $\QQ e^{t\QQ}$.  This starting
point suggests that, under fairly general conditions, we may decompose
\eqref{eq:ass:procs:0} into a component where $\QQ e^{t\QQ}$ induces
an exponential decay in time and a complementary component taking the
form of a time-affine correction term.

These observations lead to the following theorem, the proof of which appears
in the Supplement.
\begin{theorem}\label{thm:ass:error}
  Suppose that $\QQ, \JJ \in \mathcal{M}(d)$ for some $d \geq 1$.  We
  assume that we can find an element $\QQ^+ \in \mathcal{M}(d)$ such that
  $\QQ$ is a generalized inverse of $\QQ^+$, namely,
  \begin{align}\label{eq:GI:prop}
    \QQ^+ \QQ \QQ^+ = \QQ^+
  \end{align}
  and such that
  \begin{align}\label{eq:MP:proj:prop}
    e^{\tau \QQ}(\II - \QQ^+ \QQ) \!=\!  \II - \QQ^+ \QQ, \;
    (\II - \QQ \QQ^+)e^{\tau \QQ} \!=\!  \II - \QQ \QQ^+,
  \end{align}
  for any $\tau \in \bbR$. Furthermore, we suppose that $\QQ^+$ and
  $\QQ$ commute
  \begin{align}\label{eq:GI:com}
    \QQ \QQ^+ = \QQ^+ \QQ.
  \end{align}
  Finally, taking $\|\cdot\|$ be any matrix norm, we assume that
  \begin{align}\label{eq:qetq:exp:decay}
    \| \QQ e^{\tau \QQ}\| \leq C_0 e^{-\kappa \tau},
    \quad
    \text{ for all } \tau \geq 0,
  \end{align}
  where the constants $C_0 > 0, \kappa > 0$
  are independent of $\tau$.  Then, under these circumstances, 
  \begin{align}\label{eq:ass:error}
    \|\QQ^+ \JJ (\II - \QQ \QQ^{+})-& (\II -\QQ^+ \QQ) \JJ \QQ^{+}
        +t(\II -\QQ^+ \QQ) \JJ \QQ \QQ^{+}
                \notag\\
      &
        +  \nabla_\JJ e^{t \QQ} - t  e^{t\QQ} \JJ\| \leq C(1+ t)e^{-\kappa t}
\end{align}
for any $t \geq 0$.  Here, $C > 0$ is a $t$-independent
constant which is given explicitly as
\begin{align}
  C_0 \big(\| (\II -\QQ^+ \QQ) \JJ (\QQ^{+})^2\|
  \!&+\! \|(\QQ^+)^2\JJ (\II - \QQ \QQ^{+})\|
    \!+\! \|\QQ^+ \hspace{0.5mm}\JJ\|\big)
    \notag\\
    &+ C_0^2 \| \QQ^+  \JJ  \QQ^{+} \|.
      \label{eq:exp:error:ass:er}
  \end{align}
\end{theorem}

\begin{remark}\label{rmk:mat:class:dcy}
  To illuminate the scope of \cref{thm:ass:error}, we have the
  following three classes of matrices maintaining the conditions
  \eqref{eq:GI:prop}--\eqref{eq:qetq:exp:decay} as follows.
  \begin{itemize}
  \item[(i)] Suppose that $\QQ \in \mathcal{M}(d)$ is such that
    \begin{align}\label{eq:ev:d:cond}
      \Re \lambda_{d-1}(\QQ) <  \Re \lambda_d({\mathbf Q}) \leq 0,
       \lambda_d({\mathbf Q})  \text{ is simple }
    \end{align}
    and such that, if $\lambda_d({\mathbf Q})$ has an imaginary component,
    then its real part is strictly negative.  Under these
    circumstances, writing $\QQ$ in its Jordan canonical form yields,
    for some $m \geq 1$,
    \begin{equation}\label{e:Q=Jordan_decomp}
      \QQ = \M \diag (J_{1},\hdots,J_{m-1},\lambda_d(\QQ))\M^{-1}.
    \end{equation}
    Here, under \eqref{eq:ev:d:cond} each of
    these blocks $J_j$ must be invertible and so
    we may take
    \begin{align}
      \QQ^+ := \M \,
      \diag (J_{1}^{-1},\hdots,J_{m-1}^{-1},\lambda_d(\QQ)^{+})
      \, \M^{-1},
    \end{align}
    where 
    \begin{align}\label{eq:eig:gen:inv}
      \lambda_d(\QQ)^{+} =
      \begin{cases}
        0& \text{ if } \lambda_d(\QQ) = 0,\\
        \lambda_d(\QQ)^{-1}& \text{ otherwise.}
       \end{cases}
    \end{align}
  \item[(ii)] We next consider the case where $\QQ \in \mathcal{M}(d)$
    is diagonalizable and its spectrum lies strictly on the left half
    plane or at the origin.  This time we can write
    \begin{align}\label{eq:spec:decomp}
    \QQ = \M \LLambda \M^{-1} \text{ where }
      \LLambda = \diag (\lambda_1(\QQ), \ldots ,\lambda_d(\QQ))
    \end{align}
    and we set 
    \begin{align}\label{eq:gen:inv:diag}
     \! \!\! \!\QQ^+ \! \! \!= \!\M \LLambda^+\M^{-1} \text{ with }
      \LLambda^{+} \! \! \!= \! \diag (\lambda_1(\QQ)^+\!\! \! \!, \ldots
      ,\lambda_d(\QQ)^+).
      \end{align}
    The complex numbers $\lambda_j(\QQ)^+$,
    $j = 1, \ldots, d$ are defined as in \eqref{eq:eig:gen:inv}.
  \item[(iii)] Finally, we specialize to the case where
    $\QQ \in \mathcal{S}(d)$ is symmetric. In this case,
    $\QQ = \UU \LLambda \UU^*$, where $\UU$ is a unitary matrix and
    $\LLambda = \diag (\lambda_1(\QQ), \ldots ,\lambda_d(\QQ))$,
    $\lambda_j(\QQ)$ are its (real) eigenvalues.  We suppose that
    these eigenvalues are all non-positive,
    \begin{align}\label{eq:ev:d:cond:sym:case}
      \lambda_d({\mathbf Q}) \leq 0,
    \end{align}
    Here we take $\QQ^+$ as the Moore-Penrose inverse, namely,
    \begin{align}\label{eq:MP:inv:sym:case}
      \QQ^+ = \UU \LLambda^+ \UU^*,
   \end{align}
    where $\LLambda^+$ is as in \eqref{eq:gen:inv:diag}.   
  \end{itemize}
\end{remark}
In anticipation of \cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.} below
and our desired application in \cref{sec:sars:cov:app} we are
preoccupied with the dimensional dependence of the constants in
\eqref{eq:qetq:exp:decay}, \eqref{eq:ass:error}
and \eqref{eq:exp:error:ass:er} in our formulation of
\cref{thm:ass:error}.  We next provide some such desirable bounds in
case (iii) of \cref{rmk:mat:class:dcy}.  Note that analogous results
for generators $\QQ$ in the classes (i) or (ii) would seemingly
require a delicate analysis of the associated eigenspaces (i.e., of the
structure of $\M$ in \eqref{e:Q=Jordan_decomp} or
\eqref{eq:spec:decomp} respectively).  However,
\cref{rmk:non:sym:num:ev} and \cref{fig:app} provide numerical evidence
of a broader scope for dimensionally improving approximations beyond
the symmetric case, at least for certain classes of randomly drawn
matrices.
\begin{theorem}\label{thm:bride:of:frankinstein}
  Let symmetric $\QQ \in \mathcal{S}(d)$ be non-positive, i.e.,  suppose that
  \eqref{eq:ev:d:cond:sym:case} holds.  Take $\QQ^+$ as in
  \eqref{eq:MP:inv:sym:case} and define
    \begin{align}\label{eq:first:neg}
      d_{-} = \max\{ 1 \leq j \leq d | \Re \lambda_{j}(\QQ) < 0\}.
    \end{align}
    Then, for any $\JJ \in \mathcal{M}(d)$,
  \begin{align}
      \| t(\II&  -\QQ^+  \QQ) \JJ \QQ \QQ^{+}
                +  \nabla_\JJ e^{t \QQ} - t  e^{t\QQ} \JJ\|_{F} 
                \label{eq:bride:of:frankinstein:1}\\
    \leq&  
    \Big( \! \sqrt{d_{-}}|\lambda_1(\QQ)| \! \cdot\!  \Big[ 2 \sqrt{d-d_{-}} \| \QQ^+\|_F^2 +  \| \QQ^+\|_F
    \notag \\ 
              &\qquad \qquad \qquad \;
    + \sqrt{d_{-}}|\lambda_1(\QQ)|\| \QQ^+\|_F^2 \Big]   (1+t)e^{- t|\lambda_{d-}(\QQ)|}
   \notag \\ 
&\quad+  2\sqrt{d - d_{-}} \| \QQ^+\|_F  \Big)\|\JJ\|_{F},  \notag
  \end{align}
  with $\| \QQ^+\|_F^2 := \sum^{d_-}_{k=1}\frac{1}{\lambda^2_{k}(\QQ)}$, whereas
  \begin{align}
    \| t(&\II -\QQ^+ \QQ) \JJ \QQ \QQ^{+}
         +  \nabla_\JJ e^{t \QQ} - t  e^{t\QQ} \JJ\|_{\op}
         \label{eq:bride:of:frankinstein}\\
    \leq &
           \Big(
           \frac{|\lambda_1(\QQ)|(2 + |\lambda_{d_-}(\QQ)|  + |\lambda_1(\QQ)|)}{\lambda^2_{d-}(\QQ)} 
           (1+t) e^{-t |\lambda_{d_-}(\QQ)|}
           \notag
    \\ 
              &\qquad+ \frac{2}{|\lambda_{d_{-}}(\QQ)|}\Big) \|\JJ\|_{\op}.
                \notag
  \end{align}
  Under the further assumption that $\lambda_{d}(\QQ) = 0$
  and
  \begin{align}
    \mu_1 d \leq |\lambda_{d-1}(\QQ)|
    \leq |\lambda_{1}(\QQ)| \leq \mu_2 d
  \end{align}
  for some $0< \mu_1\leq \mu_2$, we have
    \begin{align}\label{eq:bride:of:frankinstein:1:rm:app}
    \| t(&\II  -\QQ^+ \QQ) \JJ \QQ \QQ^{+}
         +  \nabla_\JJ e^{t \QQ} - t  e^{t\QQ} \JJ\|_{F}
         \\
     \leq &    \Big(\frac{\mu_2}{\mu_1^2}  \cdot \Big[ 2 \sqrt{d} + \mu_1 d  
            +  \mu_2 d^2\Big](1+t)^{-t \mu_1 d} +  \frac{2}{\mu_1 \sqrt{d}} \Big) \|\JJ\|_{F},
            \notag
  \end{align}
  and that
    \begin{align}\label{eq:bride:of:frankinstein:0:rm:app}
    \| t(\II & -\QQ^+ \QQ) \JJ \QQ \QQ^{+}
         +  \nabla_\JJ e^{t \QQ} - t  e^{t\QQ} \JJ\|_{\op}\\
      \leq &  \Big( \frac{\mu_2}{\mu^2_1}\cdot\Big[   \frac{2}{d} + \mu_1  +\mu_2\Big]
             (1+t)e^{-t \mu_1 d} + \frac{2}{\mu_1 d}\Big)
            \|\JJ\|_{\op}.\notag
  \end{align}
\end{theorem}


\subsection*{High-dimensional asymptotics
  via random matrix theory}

We turn to our probabilistic bounds on the singular values of randomly
generated rate matrices, \cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.}.
Although interesting in its own right, this result leads to
consequences for the bounds in \eqref{eq:qetq:exp:decay} and
\eqref{eq:ass:error} when applied in \cref{thm:bride:of:frankinstein}.
Before proceeding, we briefly introduce further mathematical
preliminaries associated with the so-called sub-exponential random
variables.  To avoid confusion, note that the following definition uses the term in the same way as, e.g., \cite{vershynin:2018}, but that other definitions that mean quite the opposite (i.e., heavier than exponential tails) appear in the literature \cite{goldie1998subexponential}.
\begin{definition}
  \label{def:sub:exp:RV}
  A random variable $X$ is called \textit{sub-exponential} if there
  exists some constant $K > 0$ for which its tails satisfy
\begin{equation}\label{e:def_subexp_RV}
\bbP(|X|\geq t) \leq 2 e^{-t/K}, \quad \forall t \geq 0.
\end{equation}
In this case, the \textit{sub-exponential norm} of $X$ is defined by
\begin{equation}\label{e:sub-exp_norm}
\|X\|_{\psi_1} = \inf\big\{s > 0: \bbE e^{|X|/s} \leq 2\big\}.
\end{equation}
The \textit{class of sub-exponential distributions} is denoted by
\begin{align*}
L_{\psi_1} = \big\{F_X(dx): \|X\|_{\psi_1} < \infty \big\}.
\end{align*}
\end{definition}

\begin{remark}\label{rmk:exp:mom}
  In fact, by \cite[Proposition 2.7.1, p.\ 33]{vershynin:2018},
  condition \eqref{e:def_subexp_RV} is equivalent to the existence of
  some $s_0 > 0$ such that $\bbE e^{|X|/s_0} \leq 2$, namely,
  $\|X\|_{\psi_1} < \infty$ in \eqref{e:sub-exp_norm}.  As a notable
  example, if $X \sim \exp(\lambda)$, $\lambda > 0$, then it is easy
  to see that $X \in L_{\psi_1}$, indeed.
\end{remark}

We formulate our second major result as follows. 
\begin{theorem}\label{t:lambda_n-1(Q)->-infty_non-symm_a.s.}
  Let $F_X \in L_{\psi_1}$ be a distribution such that $X \geq 0$
  a.s., $\bbE X = \mu > 0$ and $\Var X = \sigma^2 > 0$. We consider a
  sequence of random matrices
  $\QQ \equiv \QQ(d) = \{q_{ij}\}_{i,j=1,\hdots,d} \in \mathcal{R}(d)$, $d \in \bbN$,
  where either
  \begin{align}\label{e:RM_theorem_general_condition}
    \begin{aligned}
  &\{q_{ij}\}_{i , j =1, \hdots, d, \hspace{0.75mm}i \neq j}
    \stackrel{\textnormal{iid}}\sim F_X
    \text{ and }\\
  &- q_{ii} = \sum_{j \in \{1,\hdots,d\} \backslash \{i\}}q_{ij},
  i=1,\hdots,d
  \end{aligned}
  \end{align}
  or we impose that $\QQ \in \mathcal{R}(d) \cap \mathcal{S}(d)$ as 
    \begin{align}
    \begin{aligned}\label{e:RM_theorem_symmetry_condition}
  &\{q_{ij}\}_{i , j =1, \hdots, d, \hspace{0.75mm}i > j}
  \stackrel{\textnormal{iid}}\sim F_X,
  q_{ij} := q_{ji} \text{ for } i < j
    \text{ and }\\
  &- q_{ii} = \sum_{j \in \{1,\hdots,d\} \backslash \{i\}}q_{ij},
  i=1,\hdots,d.
  \end{aligned}
\end{align}
    Then, in either of these cases, for any $d \in \bbN \backslash\{1\}$, we have
    \begin{align}
 \mu+ O_{\as}\Big(\sqrt{ \frac{\log d}{d}}\Big) \leq& \frac{\sigma_2(\QQ)}{d} 
 \notag \\
 \leq& \frac{\sigma_d(\QQ)}{d}
 \leq \mu+ O_{\as}\Big(\sqrt{ \frac{\log d}{d}}\Big)
 \label{e:lambda_n-1(Q)->-infty_non-symm}
      \end{align}
      almost surely. %In \eqref{e:lambda_n-1(Q)->-infty_non-symm},
      %$O_{\textnormal{a.s.}}$ is as in
      %\eqref{e:X=O_a.s.(1)_Y=o_a.s.(1)}.
\end{theorem}

\begin{remark}
  The bounds constructed in Theorem
  \ref{t:lambda_n-1(Q)->-infty_non-symm_a.s.} are strongly reminiscent
  of the bounds for eigenvalues provided in Theorem 1.5 of the seminal
  paper \cite{bordenave:caputo:chafai:2014} (see also, for instance,
  Corollary 1.6 in \cite{bryc:dembo:jiang:2006} and Corollary 1.1 in
  \cite{ding:jiang:2010}).
\end{remark}

Finally, let us observe that \cref{thm:bride:of:frankinstein},
\cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.} as well as the fact
that
\begin{align}
  \sigma_j(\QQ) = |\lambda_{d - j +1}(\QQ)|,
  \text{ for e.g. any }
  \QQ \in \mathcal{S}(d) \cap \mathcal{R}(d)
  \label{eq:eigen:to:SV:SYM:dummy}
\end{align}
combine to produce the following immediate corollary.
\begin{Corollary}\label{cor:rig:det:rand:wrapup}
  Consider any sequence of random matrices
  $\QQ \equiv \QQ(d) = \{q_{ij}\}_{i,j=1,\hdots,d} \in
  \mathcal{R}(d)$, $d \in \bbN$, as in
  \cref{t:lambda_n-1(Q)->-infty_non-symm_a.s.} under the second
  (symmetric) case \eqref{e:RM_theorem_symmetry_condition}.  Then,
  taking $\mu_1 = \mu_1(d)$ and $\mu_2= \mu_2(d)$ as the resulting
  lower and upper bounds defined by
  \eqref{e:lambda_n-1(Q)->-infty_non-symm}, we have that $\QQ$
  satisfies both \eqref{eq:bride:of:frankinstein:1:rm:app},
  \eqref{eq:bride:of:frankinstein:0:rm:app}, cf.
  \eqref{eq:eigen:to:SV:SYM:dummy} relative to this sequence of
  $\mu_1, \mu_2$ for any $\JJ \in \mathcal{M}(d)$.
\end{Corollary}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{appendixFig3.pdf}
    \caption{Frobenius norm errors obtained by first-order approximation $te^{t\QQ}\JJ$ and by affine-corrected first-order approximation
      $te^{t\QQ}\JJ - t(\II -\QQ^+ \QQ) \JJ \QQ \QQ^{+}$
      (\cref{thm:bride:of:frankinstein}) under increasingly relaxed
      assumptions.  Within each assumption set, we average over 20
      independent Monte Carlo simulations of random generator matrices
      for each dimension. Plot \textbf{a} corresponds to asymmetric
      generators with off-diagonal elements having independent and
      identically distributed (iid) standard exponential random
      variables that correspond to the sub-exponential distribution
      hypothesis. Plot \textbf{b} drops the identical distribution
      assumption by allowing each row and column of the generator
      matrix to additively contribute its own mean---itself given by a
      standard exponential---to its corresponding exponentially
      distributed entries. Plot \textbf{c} features rate
      matrices with iid Cauchy entries truncated to be
      positive. Empirically, the results of
      \cref{cor:rig:det:rand:wrapup} extend beyond the symmetric,
      iid and sub-exponential hypotheses, suggesting scope of future work.}
    \label{fig:app}
\end{figure*}

\begin{remark}\label{rmk:non:sym:num:ev}
  Our rigorous formulation of \cref{cor:rig:det:rand:wrapup} is
  limited to symmetric random rate matrices whose above diagonal
  elements are independent and identically distributed draws from a
  sub-exponential distribution. However, strong numerical evidence
  suggest that the scope of the approximations
  \eqref{eq:bride:of:frankinstein:1:rm:app},
  \eqref{eq:bride:of:frankinstein:0:rm:app} reach far beyond the
  limitations of \cref{cor:rig:det:rand:wrapup} in several different
  ways. \cref{fig:app} explores the
  consequences of relaxing various assumptions of
  \cref{cor:rig:det:rand:wrapup}.  The third plot involves folded Cauchy random variables, the heavy tails of which violate the sub-exponential assumption (\cref{def:sub:exp:RV}).  There appears to be no
  significant departure from the idea that the form
  $t(\II -\QQ^+ \QQ) \JJ \QQ \QQ^{+}$ corresponds increasingly well to
  the true approximation error (\eqref{eq:true:diff}) as the dimension
  increases.
\end{remark}

\begin{remark}\label{rmk:better:approx}
  Calculation of
  $\widetilde{\nabla}_{\JJ} e^{t\QQ} := t e^{t\QQ} \JJ$ requires
  $\order{d^3}$ operations by, e.g., computing the spectral
  decomposition $\QQ$ as in \eqref{eq:spec:decomp}.  One may then recycle this
  decomposition to determine the
  additional term $t(\II -\QQ^+ \QQ) \JJ \QQ \QQ^{+}$ for little extra cost.  In view of
  \cref{cor:rig:det:rand:wrapup} and \cref{fig:app},
  \begin{align}\label{eq:better:help:on:sale}
    \widehat{\nabla}_{\JJ} e^{t\QQ} := t e^{t\QQ} \JJ
    -t(\II -\QQ^+ \QQ) \JJ \QQ \QQ^{+}
  \end{align}
  provides an accurate approximation of $\nabla_{\JJ} e^{t\QQ}$ for
  asymptotically for large $d$. Thus, we anticipate further computational improvements when fitting
  large, gold-standard models using this
  refined approximation.  That said, we leave the efficient and scalable application of $\widehat{\nabla}_{\JJ} e^{t\QQ}$ to future work.
\end{remark}


\begin{figure}[!t]
	\centering
	\includegraphics[width=\linewidth]{lowDimVis.pdf}
	\vspace{-2em}
	\caption{Posterior density plots for surrogate-trajectory Hamiltonian Monte Carlo (HMC) using the naive approximate derivative, the corrected approximation \eqref{eq:better:help:on:sale} and the exact matrix exponential derivative for elements of a $5\times 5$ generator matrix. The near perfect overlap reflects the fact that each algorithm's transition kernel leaves the posterior distribution invariant \cite{glatt2020accept}.  To generate data, we randomly draw standard normal generator entries once and simulate 20 independent initial/final position pairs from a CTMC with time interval $t=1$.  We show the true value in red and negate diagonal elements to simplify presentation.  }\label{fig:lowDim}
\end{figure}

\section{Empirical Studies}\label{sec:emp}



\begin{figure*}[!t]
	\centering
	\includegraphics[width=\linewidth]{truthMeanFig.pdf}
	\caption{Posterior means versus truth for CTMC generator matrix elements within differing sparsity regimes and with different dimensionalities $d$, holding observation count fixed at 300. We generate posteriors using surrogate-trajectory Hamiltonian Monte Carlo with the naive matrix exponential derivative.  To affect sparsity levels, we generate generator matrix entries according to the Bayesian bridge distribution \cite{polson2014bayesian} with different exponents ($\alpha \in \{1,1/2,1/4\}$), normalizing by the largest absolute values to ease comparison. Smaller $\alpha$ values encode more peaked distributions with heavier tails and thus enforce greater sparsity.   Plot \textbf{c} reflects the fact that the Bayesian bridge prior with exponent $\alpha=1/4$ helps identify non-null parameters in small sample contexts \cite{magee2023random}.  With this intuition in mind, we specify such a prior on generator random effects in \cref{sec:sars:cov:app}.}
	\label{fig:truthMean}
\end{figure*}


Before applying the naive matrix exponential derivative approximation to the phylogeographic analysis of SARS-CoV-2, we carry out a few targeted studies that illustrate: the empirical performance of the approximate derivative and its affine correction \eqref{eq:better:help:on:sale} (\cref{fig:app}); agreement between CTMC generator matrix empirical posterior distributions generated by surrogate-trajectory Hamiltonian Monte Carlo (HMC) algorithms using approximate derivatives and the truth (\cref{fig:lowDim}); and point estimation of generator matrix element values under different sparsity regimes and different CTMC state space dimensionalities $d$ (\cref{fig:truthMean}). 

Here, we fill in remaining simulation details not included in figure captions. In the simulations contributing to \cref{fig:app}, we randomly generate new, independent direction matrices $\JJ$ at each time step within each of the 20 independent runs. The results are not sensitive to $\JJ$ in general.  We also note that under \cref{def:sub:exp:RV} the Cauchy distribution is \emph{not} sub-exponential and therefore represents a deviation from core assumptions of \cref{sec:rig:results}.  Using varying distributions on the elements of generator matrices $\QQ$, the simulations contributing to \cref{fig:lowDim} and \cref{fig:truthMean} both randomly generate $N$ independent initial states $\y^0_1,\dots,\y^0_N$ according to uniform distributions over their respective CTMC state spaces. For each of these initial states $\y_0$, we then simulate from the CTMC for time interval $t=1$ to obtain samples $\y^1_1,\dots,\y^1_N$.  The likelihood then takes the form $\prod_n (\y^{0}_n)^T e^{\QQ} \y^{1}_n$.  For the simulation contributing to \cref{fig:lowDim}, we specify standard normal priors and sample from the posterior by generating 100,000 iterations from each algorithm.  For the simulation contributing to \cref{fig:truthMean}, we generate 500,000 MCMC samples using surrogate-trajectory HMC with the naive matrix exponential derivative and calculate the posterior mean of each generator matrix element using the final 100,000 samples.  




\section{Application: Global Spread of SARS-CoV-2}
\label{sec:sars:cov:app}



\cite{magee2023random} consider phylogenetic models that involve CTMC
priors and show that the first-order approximation
\eqref{eq:firstOrder} of the matrix exponential derivative
\eqref{eq:grad:def} performs remarkably well within surrogate HMC (see Supplement), achieving an over 30-fold
efficiency gain compared to random-walk Metropolis for a 14-state
model with over 180 model parameters.  Here, we demonstrate similar
strong performance of the first-order approximation within surrogate
HMC for a 44-state model with almost 1,900 model parameters.



\subsection*{Phylogenetic CTMC}

Start with a (possibly unknown) rooted and bifurcating phylogenetic
tree $\phylogeny$ consisting of $N$ leaf nodes that correspond to
observed biological specimens and $N-1$ internal nodes that correspond
to unobserved ancestors.  The tree also contains $2N-2$ branches of
length $t_v$ connecting each child node $v$ to its parent $u$.

Given $\phylogeny$, we model the evolution of $d$ characters along
each branch of the tree according to a CTMC model with $d\times d$
generator matrix $\QQ$ and stationary distribution
$\ppi=(\pi_1,\dots,\pi_d)=\lim_{t\rightarrow
  \infty}\widetilde{\ppi}e^{t\QQ}$, for $\widetilde{\ppi}$ any
arbitrary probability vector.  Examples of characters are the $d=4$
nucleotides within a set of aligned genome sequences
\cite{jukes1969evolution} and the set of $d=15$ geographic regions
visited by an influenza subtype \cite{lemey2014unifying}.  We may
scale $t_v$ to be raw time (e.g., years) or the expected number of
substitutions with respect to $\ppi$ depending on the given problem.
In the former case, one may augment the model with a rate scalar
$\gamma$ that modulates the expected number of substitutions across
all branches, and the finite-time transition probability matrix along
branch $v$ becomes $\P_v:=e^{\gamma t_v \QQ}$.  In the following, we
further posit $\QQ=\QQ(\ttheta)$ for $\ttheta$ a vector of parameters.
 
Let data $\Y$ be the $d\times N$ matrix with columns $\y_n$, $n \in \{1,\dots,N\}$, each
having a single non-zero entry (set to 1) corresponding to the
observed state of the biological specimen.  One may use
any node $v$ to express the likelihood
 \begin{align}
p(\Y|\ttheta) = \p_v^T \q_v \, ,
 \end{align}
 where $\p_v$ and $\q_v$ are the post-order and pre-order partial
 likelihood vectors, respectively \cite{ji2020gradients}.  The former describes the
 probability of the observed states for all observed specimens (i.e.,
 leaf nodes) that descend from node $v$, conditioned on the state at
 node $v$. The latter describes analogous probabilities for all
 observed specimens not descending from node $v$. For leaf nodes,
 $\p_n:=\y_n$, $n \in \{1,\dots,N\}$, and one may specify the root node's pre-order partial likelihood to be any arbitrary probability vector \emph{a priori}. Let `$\circ$' denote the Hadamard or elementwise product between matrices or vectors of equal dimensions.  If we suppose that node $u$ gives rise to two child
 nodes, $v$ and $w$, then
\begin{align}\label{eq:recursions}
  \p_u = \P_v \p_v \circ \P_w \p_w\, ,
  \quad \q_v= \P_v^T \left( \q_u \circ  \P_w \p_w\right) \, .
\end{align}
Using the chain rule and the fact that $\p_v$ does not depend on
$\P_v$, one may write the likelihood's derivative with respect to a
single parameter $\theta_k$ thus:
\begin{align}\label{eq:phyloGrad}
	\frac{\partial}{\partial \theta_k}  p(\Y|\ttheta) 
  &\propto   \sum_{v=1}^{2N-2}
    \mbox{tr} \left( \frac{\partial (\p_v^T\q_v)}{\partial \P_v}
    \frac{\partial \P^T_v}{\partial \theta_k} \right) \\ \notag
  &= \sum_{v=1}^{2N-2} \mbox{tr} \left(  (\q_u\circ \P_w\p_w)
    \p_v^T\bigg( \frac{\partial e^{\gamma t_v \QQ}}{\partial \theta_k}\bigg)^{\!T}\right)  \\ \nonumber
  &=\sum_{v=1}^{2N-2} \p_v^T
    \Biggl(\sum_{i,j=1}^d  \frac{\partial e^{\gamma t_v \QQ}}{\partial q_{ij}} \frac{\partial q_{ij}}{\partial \theta_k} \Biggr)^{\!T}
    \hspace{-0.3em}(\q_u\circ \P_w\p_w)  \, ,
\end{align}
where we suppress the dependence of $u$ and $w$ on $v$.

Whereas the recursions of \eqref{eq:recursions} facilitate fast
likelihood computation, inferring $\ttheta$ using gradient-based
approaches such as HMC requires a large number of repeated evaluations
of the matrix exponential derivative.  These computations become
particularly onerous when one opts for a gold-standard mixed-effects
model \cite{magee2023random} and specifies
\begin{align}\label{eq:mixed}
\log q_{ij} = b_{ij} + \epsilon_{ij} \,, \quad i\neq j\, .
\end{align} 
Here, the fixed effects $b_{ij}$ are elements of some non-random
matrix $\B$, and the random effects $\epsilon_{ij}$ are mutually
independent \emph{a priori} and inferred as model parameters.  The
dimension $K$ of $\ttheta$ in this model is $\mathcal{O}(d^2)$, so the $\mathcal{O}(KNd^5)$ cost of the log-likelihood derivative \eqref{eq:phyloGrad}
becomes a massive $\mathcal{O}(Nd^7)$.  In this context,
\cite{magee2023random} show that an approximate log-likelihood derivative based on the first-order approximation to the matrix exponential helps achieve a considerable speedup over the exact
derivative, requiring only $\mathcal{O}(d^4 + Nd^3)$ floating-point operations yet facilitating high-quality proposals in the context
of surrogate HMC.

In the following section, we use this method to analyze the global
spread of SARS-CoV-2 and show that the first-order approximation
maintains its performance for an even higher-dimensional problem than
previously considered.

\subsection*{Bayesian analysis of SARS-CoV-2 contagion}

\begin{figure*}[!t]
	\centering
	\includegraphics[width=\linewidth]{fixedEffects.pdf}
	\vspace{-2em}
	\caption{Matrix predictors described in \eqref{eq:linear} combine in a linear manner to form the fixed-effect matrix $\B$ featured within the mixed-effects regression model \eqref{eq:mixed}.  Air traffic proximities \emph{(\textbf{a})} are proportional the number of air passengers exchanged between airports within respective regions \cite{holbrook2021massive}.  Intracontinental proximities \emph{(\textbf{b})} take values between -1 for regions on different continents to 1 for adjacent regions.  The Hubei asymmetry \emph{(\textbf{c})} roughly characterizes the Hubei quarantine of early 2020.}\label{fig:FE}
\end{figure*}



We use the phylogenetic CTMC framework to model the early spread of
SARS-CoV-2---the virus responsible for the ongoing COVID-19
pandemic---based on $N=285$ observed viral samples collected from $31$
regions worldwide between December 24, 2019 and March 19, 2020. These
regions comprise 13 provinces within China and 18 countries without.
Understanding the manner in which viruses travel between human
populations is an object of ongoing study, and phylogeographic
analyses point to the central role of travel networks including those
measured by airline passenger counts \cite{holbrook2021massive} or
google mobility data \cite{worobey2020emergence}.  Here, we include
three such predictors of travel in our CTMC model by expanding the
fixed effects in regression model \eqref{eq:mixed} to take the form
\begin{align}\label{eq:linear}
	\B = \theta_1 \X_1 + \theta_2  \X_2 + \theta_3 \X_3 
\end{align} 
for $\X_1$, $\X_2$ and $\X_3$ fixed $44\times 44$ matrix predictors and $\theta_1$, $\theta_2$ and $\theta_3$
 real-valued regression coefficients. Note we have expanded the
number of regions between which viruses may travel to $d=44$ by
including two additional Chinese provinces and 11 additional
countries.  Figure \ref{fig:FE} presents the three predictors of
interest: $\X_1$ contains air travel proximities between locations as
measured by annualized air passenger counts between airports contained
within a region \cite{holbrook2021massive}; $\X_2$ contains
intracontinental proximities arising from physical distances when two
regions inhabit the same continent and fixed at the minimum otherwise;
finally, $\X_3$ describes the Hubei asymmetry, i.e., the non-existence
of human travel out of the Hubei province in early 2020.

\begin{figure*}[!t]
	\centering
	\includegraphics[width=\linewidth]{postViz.pdf}
	\vspace{-2em}
	\caption{Posterior inference. Posterior densities
          \emph{(\textbf{a})} for the three fixed-effect regression
          coefficients corresponding to the predictor matrices of
          Figure \ref{fig:FE} reflect largely positive associations
          between predictors and infinitesimal rate matrix, although
          air traffic proximity has the only statistically significant
          coefficient with posterior mean of 0.76 and 95\% credible
          interval of (0.50, 1.03).  The posterior mean
          \emph{(\textbf{b})} infinitesimal rate matrix closely
          resembles the air traffic predictor, while reflecting the
          Hubei asymmetry to a lesser extent.}\label{fig:post}
\end{figure*}


In the context of a Bayesian analysis, we specify independent normal
priors on $\theta_1$, $\theta_2$ and $\theta_3$ with means of 0 and
variances of 2.  We also assume that the 1,892 random effects
$\epsilon_{ij}$ follow sparsity inducing Bayesian bridge priors with
global scale parameter $\tau$ and exponent $\alpha=0.25$.  Here, we
follow \cite{nishimura2022shrinkage} and specify a Gamma prior on
$\tau^{-\alpha}$ with a shape parameter of 1 and a rate parameter of
2. Finally, we place a flat prior on the rate scalar $\gamma$.
Inferring the posterior distribution of all 1,897 model parameters
requires an advanced MCMC strategy. Namely, we adopt an
HMC-within-Gibbs approach, updating the scalars $\gamma$ and $\tau$
independently but updating all 1,895 regression parameters (both fixed
and random effects) using surrogate HMC accomplished with the
first-order approximation
\begin{align*}
  \gamma t_v  e^{\gamma t_v \QQ} \JJ_{ij}
  \approx \frac{\partial e^{\gamma t_v \QQ}}{\partial q_{ij}} 
\end{align*}
within \eqref{eq:phyloGrad}.

We generate 8 million MCMC samples in this manner, saving 1 in 10,000
Markov chain states, in order to guarantee a minimum effective sample
size (ESS) greater than 100.  By far, the worst-mixing parameter is
the global scale $\tau$, which obtains an ESS of 185.  The three
fixed-effects regression coefficients $\theta_1$, $\theta_2$ and
$\theta_3$ obtain ESS's of 721, 721 and 644, respectively.  The median
and minimum ESS for the 1,892 random effects $\epsilon_{ss'}$ are 721
and 190, respectively.  We note that, after thinning and removing
burn-in, the sample only consists of 721 states, so ESS of 721 implies
negligible autocorrelation between samples.

The left plot of Figure \ref{fig:post} presents posterior densities
for the fixed-effect coefficients from regression \eqref{eq:mixed}.
The air traffic proximity, intracontinental proximity and Hubei
asymmetry coefficients have posterior means and 95\% credible
intervals of 0.76 (0.50, 1.03), 0.04 (-0.04, 0.12) and 0.27 (-0.39,
0.78), respectively. While these results suggest a positive
association between each predictor matrix and the infinitesimal
generator matrix $\QQ$, the only predictor with a statistically
significant association is air traffic proximity.  This result agrees
with a previous phylogeographic analysis of the global spread of
influenza \cite{holbrook2021massive}.  The right plot of Figure
\ref{fig:post} presents the posterior mean for generator $\QQ$.  As
one may expect, the matrix looks similar to that of the air traffic
predictor matrix in Figure \ref{fig:FE}, but one may also see the
influence of the Hubei asymmetry in, e.g., the squares corresponding
to travel between Guangdong and Hubei provinces.  Finally, we randomly
generate regions of unobserved ancestors from their posterior
predictive distributions every 100-thousandth MCMC iteration.
After collapsing regions into 8 major blocks, Figure \ref{fig:tree} projects the empirical posterior predictive mode of these blocks onto the phylogenetic tree $\phylogeny$.  The general pattern looks similar to that of Figure 1 from \cite{lemey2020accommodating}, although the geographic blocking scheme differs slightly.



\begin{figure*}[!t]
	\centering
	\includegraphics[width=0.7\textwidth]{summary2.tree.pdf}
	\vspace{-0.5em}
	\caption{Posterior predictive modes for (unobserved) ancestral
          locations color a phylogenetic tree that describes the
          shared evolutionary history of 285 SARS-CoV-2
          samples.}\label{fig:tree}
\end{figure*}

In addition to these scientific questions of interest, we are
interested in the performance of the first-order approximation as a
surrogate gradient for HMC in such a high-dimensional setting. Whereas we know that the surrogate-trajectory HMC transition kernel leaves its target distribution invariant regardless of the approximation quality \cite{glatt2020accept}, transitions that rely on poor gradient approximations result in small acceptance rates, more random walk behavior and high autocorrelation between samples.  Since ESS is inversely proportional to a Markov chain's asymptotic autocorrelation, larger ESS suggest a useful gradient approximation.  To
isolate the approximation's performance, we fix the Bayesian bridge global-scale
$\tau$ at 2.5$\times10^{-5}$.  We generate a Markov chain with 80,000
states, saving every tenth state and removing the first 1,000 states as
burn-in.  Despite the relatively small number of iterations, we
observe large ESS that suggest satisfactory accuracy of the
first-order approximation within the context of high-dimensional
surrogate HMC.   The ESS for the three fixed-effect regression
coefficients $\theta_1$, $\theta_2$ and $\theta_3$ are 1,053, 1,343
and 498, respectively.  The median and minimum ESS for the 1,892
random effects $\epsilon_{ij}$ are 1,514 and 1,161, respectively.


\section*{Discussion}

We develop tight probabilistic bounds on the error associated
with a simplistic approximation to the matrix exponential derivative
for a large class of CTMC infinitesimal generator matrices with random
entries.  Our ``blessing of dimensionality'' result shows that this
error improves for higher-dimensional matrices.  We apply the
numerically naive approach to the analysis of the global spread of
SARS-CoV-2 using a mixed-effects model of unprecedented dimensions.
The results obtained herein suggest the further study of CTMCs through
the lens of random matrix theory.  Furthermore, this analysis suggests a refinement of the first-order
approximation to the matrix exponential derivative that may be particularly useful within
modern, high-dimensional settings.




\acknow{GD was partially supported by the Simons Foundation
  collaboration grant $\#$714014. NEGH received support for this work
  under NSF DMS 2108790.  AJH is supported by a gift from the Karen
  Toffler Charitable Trust and by grants NIH K25 AI153816, NSF DMS
  2152774 and NSF DMS 2236854. AFM and MAS are partially supported
  through grants NIH R01AI153044 and R01AI162611.}

\showacknow{} % Display the acknowledgments section

% Bibliography
\bibliography{refs}










%\matmethods{



\end{document}
