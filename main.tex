% !TeX document-id = {d42653b9-9ea4-48c2-860b-3d6e6e9d8ab0}
% !TeX TXS-program:compile = txs:///pdflatex/[--shell-escape]
\documentclass[12pt]{article} % For LaTeX2e
%\usepackage{neurips_2021}
\usepackage[colorlinks, citecolor={blue}]{hyperref}
\usepackage{url}
\usepackage{amsfonts,amscd,amssymb}
\usepackage{amsthm,amsmath,natbib}
\usepackage{algorithm,algorithmicx,algpseudocode}
\usepackage{bm}
\usepackage{bbm} %bb font numbers
\usepackage[table]{xcolor}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
%\usepackage[nolists]{endfloat}
\usepackage{listings}
\usepackage[textsize=tiny]{todonotes}
\usepackage{tikz}
\usetikzlibrary{shapes.misc}
\usepackage{etoolbox}
\usepackage{appendix}
\usepackage[format=plain,
labelfont={it},
textfont=it]{caption}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{xr}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{authblk}
\usepackage{mathbbol}
\usepackage{thmtools}



\usetikzlibrary{matrix}
\usetikzlibrary{backgrounds}
\usetikzlibrary{calc}
\usetikzlibrary{arrows,shapes}
\usetikzlibrary{decorations}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{fit}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{shapes.misc}
\usetikzlibrary{shapes.geometric}

\newtoggle{quickdraw}
%\toggletrue{quickdraw} % Uncomment this to render more quickly (non-random)


\definecolor{lightgrey}{rgb}{0.9,0.9,0.9}
\definecolor{darkgreen}{rgb}{0,0.3,0}
%\definecolor{darkred}{rgb}{0.3,0,0}

\definecolorset{rgb}{}{}{darkred,0.8,0,0;darkgreen,0,0.5,0;darkblue,0,0,0.5}

%\doublespacing

\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{mydef}{Definition}
\newtheorem*{assumption}{Assumption}
\newtheorem{clm}{Claim}

\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}
\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand*{\fplus}{\genfrac{}{}{0pt}{}{}{+}}
\newcommand*{\fdots}{\genfrac{}{}{0pt}{}{}{\cdots}}
\newcommand{\mb}{\mathbf}
\newcommand{\mc}{\mathcal}
\newcommand{\dx}{\mbox{d}}

\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\numTaxa}{N}
\newcommand{\numTraits}{D}
\newcommand{\numDatasets}{M}
%\newcommand{\numLatent}{D}
\newcommand{\taxonIndex}{i}
\newcommand{\traitIndex}{j}
\newcommand{\traitData}{\vec{Y}}
\newcommand{\traitDatum}{y}
\newcommand{\datasetIndex}{m}
\newcommand{\exemplar}{\text{e}}

\newcommand{\sequences}{\vec{S}}
\newcommand{\latentData}{\vec{X}}
\newcommand{\latentdata}{\vec{x}}
\newcommand{\latentDatum}{x}
\newcommand{\phylogeneticParameters}{\boldsymbol{\phi}}
\newcommand{\phylogeny}{{\cal G}}
\newcommand{\tree}{\phylogeny}
%\newcommand{\otherParameters}{\boldsymbol{\
\newcommand{\transpose}{^{t}}

\newcommand{\distanceMatrix}{\mathbf{Y}}
\newcommand{\distance}{y}
\newcommand{\summant}{r}



\newcommand{\cdensity}[2]{\ensuremath{p(#1 \,|\,#2)}}
\newcommand{\density}[1]{\ensuremath{p(#1 )}}

\newcommand{\treeNode}{\nu}

\newcommand{\traitVariance}{\mathbf{\Sigma}}
\newcommand{\nodeIndex}{c}

%\newcommand{\parent}[1]{\mbox{\tiny pa}(#1)}
\newcommand{\parentBig}[1]{\mbox{pa}(#1)}

\newcommand{\sibling}[1]{\mbox{\tiny sib}(#1)}
\newcommand{\siblingBig}[1]{\mbox{sib}(#1)}

\newcommand{\rootMean}{\boldsymbol{\mu}_0}
\newcommand{\rootVarianceScalar}{\tau_0}
\newcommand{\unsequencedVarianceScalar}{\tau_{\exemplar}}
\newcommand{\treeVariance}{\vec{V}_{\tree}}
\newcommand{\hatTreeVariance}{\hat{\vec{V}}_{\tree}}
\newcommand{\mdsSD}{\sigma}
\newcommand{\mdsVariance}{\mdsSD^2}
\newcommand{\residual}{\hat{\traitDatum}}
\newcommand{\modelDistance}{\delta}
\newcommand{\cdf}{\phi}
\newcommand{\normalCDF}[1]{\Phi \left( #1 \right)}

\newcommand{\order}[1]{{\cal O}\hspace{-0.2em}\left( #1 \right)}

\newcommand{\rootNode}{\nu^{\datasetIndex}_{2 \numTaxa_{\datasetIndex} -1 }}
\newcommand{\pathLength}[1]{d(F, #1 )}
\newcommand{\pathLengthNew}[2]{
d_{F}
(
{#1}, {#2}
)
}
\newcommand{\J}{\vec{J}}
\newcommand{\pprime}{^{\prime}}
\newcommand{\otherIndex}{i \pprime}
\def\kronecker{\raisebox{1pt}{\ensuremath{\:\otimes\:}}}

\definecolor{trevorblue}{rgb}{0.330, 0.484, 0.828}
\definecolor{trevoryellow}{rgb}{0.829, 0.680, 0.306}


\allowdisplaybreaks

%\makeatletter
%\def\title@font{\Huge}
%\let\ltx@maketitle\@maketitle
%\def\@maketitle{\bgroup%
%	\let\ltx@title\@title%
%	\def\@title{\resizebox{\textwidth}{!}{%
%			\mbox{\title@font\ltx@title}%
%	}}%
%	\ltx@maketitle%
%	\egroup}
%\makeatother


\title{Approximating the matrix exponential derivative with respect to a structured matrix}


%\date{}



\author{Andrew J.~Holbrook}

 
\affil{UCLA Biostatistics}





\renewcommand\Authands{ and }


\graphicspath{{figures/}}

\begin{document}


\maketitle




\begin{abstract}

We investigate the accuracy of a first-order approximation to the directional derivative of the matrix exponential evaluated on continuous-time Markov chain (CTMC) generator matrices.


\end{abstract}



\section{Introduction}\label{sec:intro}

%\newcommand{\x}{\mathbf{x}}
%\renewcommand{\v}{\mathbf{v}}

%\newcommand{\TTTheta}{\boldsymbol{\Theta}}
%\newcommand{\tr}{\mbox{tr}}
%\newcommand{\X}{\mathbf{X}}
%\renewcommand{\u}{\mathbf{u}}
\newcommand{\QQ}{\mathbf{Q}}
\newcommand{\DD}{\mathbf{D}}
\newcommand{\MM}{\mathbf{M}}
\newcommand{\JJ}{\mathbf{J}}
\newcommand{\II}{\mathbf{I}}
\newcommand{\RR}{\mathbf{R}}
%\newcommand{\haar}{\mathcal{H}}
%\newcommand{\orthog}{\mathcal{O}}
%\newcommand{\SSigma}{\boldsymbol{\Sigma}}
\newcommand{\Zero}{\boldsymbol{0}}
\newcommand{\ttheta}{\boldsymbol{\theta}}
\newcommand{\Llambda}{\boldsymbol{\Lambda}}
\newcommand{\vecc}{\mbox{vec}}
\newcommand{\CC}{\mathbf{C}}
\newcommand{\BB}{\mathbf{B}}
\renewcommand{\AA}{\mathbf{A}}
\newcommand{\GG}{\mathbf{G}}

Let $\QQ=[q_{ij}]$ be the rate matrix for an $S$-dimensional continuous time Markov chain, where $q_{ij}>0$ for $i\neq j$, and $q_{ii} = -\sum_{j\neq i} q_{ij}$.  In our application of interest, $\QQ$ is almost surely diagonalizable, i.e., $\QQ=\MM \DD \MM^{-1}$ for 
\begin{align*}
	\DD = \begin{pmatrix}
		d_1& 0 &\dots & & \\
		0  & d_2 &0  & \dots& \\
		\vdots &0 & \ddots & \\
		& \vdots& & d_{S-1} &0 \\
		&&&0&0
	\end{pmatrix} \, ,
\end{align*}
where the structure of $\QQ$ implies eigenvalues
\begin{enumerate}
	\item $d_s\in \mathbb{C}$ with $\mbox{Re}(d_s)<0$ for $s\in\{1,\dots,S-1\}$, and
	\item $d_S =0$ corresponding to the eigenvector $\boldsymbol{1}=(1,\dots,1)^T$. 
\end{enumerate} 
We may further define a generalized inverse $\QQ^+=\MM \DD^{+} \MM^{-1}$ of $\QQ$ using $\DD^+$, the Moore-Penrose pseudoinverse obtained by inverting the non-zero elements of $\DD$.   Finally, we note that diagonalizability implies $\DD$ and $\DD^+$ commute, i.e., $\DD^+\DD=\DD\DD^+$.


 We are interested in efficiently approximating the directional derivative of the matrix exponential
\begin{align*}
	e^{t\QQ} = \sum_{k=0}^\infty \frac{t^k\QQ^k}{k!}
\end{align*}
for arbitrary $t>0$ using the formula \citep{najfeld1995derivatives}
\begin{align}\label{eq:deriv}
	\nabla_{\JJ} e^{t\QQ}  =  e^{t\QQ}  \sum_{k=0}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} \, .
\end{align}
Here, $\JJ$ gives the direction and $\{\JJ,\QQ^k\}$ is the matrix commutator series satisfying the recursion
\begin{align*}
	\{\JJ,\QQ^0\} &= \JJ \, , \\ 
	\{\JJ,\QQ^k\} &= [\{\JJ,\QQ^{k-1}\} , \QQ]  = \{\JJ,\QQ^{k-1}\} \QQ - \QQ \{\JJ,\QQ^{k-1}\} \, .
\end{align*}
Thus, the first-order approximation to derivative \eqref{eq:deriv} is 
\begin{align}\label{eq:firstOrder}
	\widetilde{\nabla}_{\JJ} e^{t\QQ}= t e^{t\QQ}\JJ \, .
\end{align}
We want to bound the truncation error
\begin{align*}
\mbox{err}(t,\QQ,\JJ)	:=\lVert \nabla_{\JJ} e^{t\QQ} - \widetilde{\nabla}_{\JJ} e^{t\QQ} \rVert \, ,
\end{align*}
 where $\lVert \cdot \rVert$ denotes an appropriate matrix norm.  In this context, we find that naive bounds (Appendix \ref{sec:loose}) that do not exploit the structure of $\QQ$  are rather loose (Figure \ref{fig:frob}).  
 In our efforts to fully leverage the structure of $\QQ$, we will make use of the general formula for the matrix commutator series  \citep{volkin1968iterated}
\begin{align}\label{eq:commSeries}
	\{ \JJ, \QQ^k\} = \sum_{r=0}^k (-1)^{k+r}  {k \choose r} \QQ^{k-r} \JJ \QQ^r  \, .
\end{align}

\subsection{An empirically tight asymptotic estimate}

We begin by noting
\begin{align}\label{eq:ub1}
	\mbox{err}(t,\QQ,\JJ) &=  \lVert  e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} \rVert \\ \nonumber
	&\leq  \lVert  e^{t\QQ}\JJ  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \QQ^k \rVert +   \lVert  e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} -\JJ\QQ^k\rVert \\ \nonumber
		&=  \lVert  e^{t\QQ}\JJ \QQ^+  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \QQ^{k+1} \rVert +   \lVert  e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} -\JJ\QQ^k\rVert \\ \nonumber
		&=  \lVert  e^{t\QQ}\JJ \QQ^+ (e^{t\QQ} - t\QQ -\II) \rVert +   \lVert  e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} -\JJ\QQ^k\rVert \\ \nonumber
			&\leq \lVert  e^{t\QQ}\JJ \QQ^+ ( t\QQ +\II) \rVert  + \lVert  e^{t\QQ}\JJ \QQ^+ e^{t\QQ} \rVert  +   \lVert  e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} -\JJ\QQ^k\rVert \, .
\end{align}
Empirical experiments using the Frobenius and infinity norms (Figures \ref{fig:frob} and \ref{fig:inf}, respectively) show that the first term
\begin{align}
	\widetilde{\mbox{err}}(t,\QQ,\JJ) := \left\Vert e^{t\QQ} \JJ \QQ^+(t\QQ+\II)  \right\Vert \, ,
\end{align}
although not a strict upper bound, is asymptotically tight for the true error as $t\rightarrow \infty$. We would, therefore, like to show that the second and third terms go to zero as $t$ diverges.

%\section{An instructive informal approach}
%The naive bounds in Appendix \ref{sec:loose} appear useful when $t$ is very small but explode for moderate values of $t$ (Figure \ref{fig:frob}).
% When $t$ is large enough that the CTMC has reached stationarity, we have 
% \begin{align*}
% 	\frac{d}{dt}e^{t\QQ} =  \QQ e^{t\QQ}=e^{t\QQ} \QQ  = \Zero \, .
% \end{align*}
% If we further assume $\QQ$ is diagonalizable, i.e., $\QQ=\MM \DD \MM^{-1}$ for 
% \begin{align*}
% 	\DD = \begin{pmatrix}
% 		d_1& 0 &\dots & & \\
% 		0  & d_2 &0  & \dots& \\
% 		\vdots &0 & \ddots & \\
% 		 & \vdots& & d_{S-1} &0 \\
% 		 &&&0&0
% 	\end{pmatrix} \, ,
% \end{align*}
% where $d_1<\dots <d_{S-1}<0$ are unique, then we may define a the generalized inverse $\QQ^+=\MM \DD^{+} \MM^{-1}$ of $\QQ$. Here, $\DD^+$ is the Moore-Penrose pseudoinverse obtained by inverting the non-zero elements of $\DD$.  Using this definition, it follows that
%		\begin{align*}
%			\mbox{err}(t,\QQ,\JJ)	&=\lVert \nabla_{\JJ} e^{t\QQ} - \widetilde{\nabla}_{\JJ} e^{t\QQ} \rVert	\\
%			&=\Vert\nabla_{\JJ} e^{t\QQ} - t e^{t\QQ}\JJ \Vert = \left\Vert e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} \right\Vert \\
%			&=\left\Vert e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \order{\QQ^k \JJ \QQ^k}\right\Vert  = \left\Vert e^{t\QQ} \JJ  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!}  \order{ \QQ^k}\right\Vert  \\
%		&= \left\Vert e^{t\QQ} \JJ \QQ^+ \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \order{\QQ^{k+1}} \right\Vert = \left\Vert e^{t\QQ} \JJ\QQ^+ \order{ e^{t\QQ}-t\QQ-\II } \right\Vert  \, .
%	\end{align*}
%But $\QQ e^{t\QQ}= \Zero$ implies $\QQ^+e^{t\QQ}= \Zero$ because $\QQ$ and $\QQ^+$ share the same zero eigenvalue. We therefore have
%\begin{align}\label{eq:err3}
%	\mbox{err}(t,\QQ,\JJ) = \left\Vert e^{t\QQ} \JJ \QQ^+\order{t\QQ+\II } \right\Vert 
%\end{align}
%
%\begin{remark}
%Ignoring the big-O notation, the matrix $e^{t\QQ} \JJ \QQ^+(t\QQ+\II)$ is nilpotent, so its spectral radius is 0.  Then for any $\epsilon>0$ a norm exists that is less than $\epsilon$ when applied to the matrix argument.
%\end{remark}
%
%Surprisingly, for the special case of the Frobenius norm, the approximation
%\begin{align}
%	\widetilde{\mbox{err}}(t,\QQ,\JJ) := \left\Vert e^{t\QQ} \JJ \QQ^+(t\QQ+\II)  \right\Vert_F
%\end{align}
%appears to be asymptotically tight in the limit $t\rightarrow \infty$ although it is not an upper bound (Figure \ref{fig:frob}).  Notably, this pattern does not hold for other matrix norms such as the infinity norm (Figure \ref{fig:inf}).  For this reason, we focus on the Frobenius norm in what follows.






\section{Using the structure of $\QQ$}

We use the fact that
\begin{align*}
	e^{t\QQ}\QQ = \MM \exp(t\DD) \DD \MM^{-1} =  \MM \begin{pmatrix}
	e^{td_1}	d_1& 0 &\dots & & \\
		0  & e^{td_2}d_2 &0  & \dots& \\
		\vdots &0 & \ddots & \\
		& \vdots& & e^{td_{S-1}}d_{S-1} &0 \\
		&&&0&0
	\end{pmatrix} \MM^{-1} \, .
\end{align*}
Thus, assuming use of a submultiplicative norm leads to the result
\begin{align*}
	\lVert e^{t\QQ}\QQ \rVert &\leq \left\Vert  \begin{pmatrix}
		e^{td_1}	d_1& 0 &\dots & & \\
		0  & e^{td_2}d_2 &0  & \dots& \\
		\vdots &0 & \ddots & \\
		& \vdots& & e^{td_{S-1}}d_{S-1} &0 \\
		&&&0&0
	\end{pmatrix}  \right\Vert  \lVert \MM\rVert   \lVert \MM^{-1}\rVert  \, .
\end{align*}
For, e.g., the Frobenius norm, we have
\begin{align*}
\lVert e^{t\QQ}\QQ \rVert_F	\leq \sqrt{S-1} \max_s \{|e^{td_{s}} d_{s}| \}  \lVert \MM\rVert_F   \lVert \MM^{-1}\rVert_F  \, ,
\end{align*}
where we  use the fact that $\lVert \cdot \rVert_F \leq \sqrt{r} \lVert \cdot \rVert_2$ for any rank $r$ matrix and $\lVert \cdot \rVert_2$ the spectral norm.  We therefore write
\begin{align}
	\lVert e^{t\QQ}\QQ \rVert_F = \order{\max_s \left\{|e^{td_{s}} d_{s}| \right\}} \,,  \quad 	\lVert e^{t\QQ}\QQ^+ \rVert_F = \order{\max_s \left\{ \left| e^{td_{s}} \frac{1}{d_{s}}\right| \right\}} \, .
\end{align}
Because $\mbox{Re}(d_s)<0$ for $s\in \{1,\dots,S-1\}$, we have
\begin{align}
	\lim_{t\rightarrow \infty}  	\lVert e^{t\QQ}\QQ \rVert_F = 	\lim_{t\rightarrow \infty}  	\lVert e^{t\QQ}\QQ^+ \rVert_F = 0\, ,
\end{align}
and, by equivalence of norms, we have
\begin{align}
	\lim_{t\rightarrow \infty}  	\lVert e^{t\QQ}\QQ \rVert = 	\lim_{t\rightarrow \infty}  	\lVert e^{t\QQ}\QQ^+ \rVert = 0\, ,
\end{align}
in general for any matrix norm $\lVert \cdot \rVert$.



%.  Employing these facts will require us to rewrite the series in $\QQ^k \JJ \QQ^k $ as a matrix exponential, and for this we use the identity
%\begin{align*}
%	\vecc \left(\AA \BB \CC \right) = \left( \CC^T \otimes \AA \right) \vecc (\BB) \, .
%\end{align*}
%Dropping the big-O notation, we have
%\begin{align*}
%	\mbox{err}(t,\QQ,\JJ)&=  \left\Vert \QQ^+ e^{t\QQ} \left( \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \QQ^{k+1}\JJ\QQ^{k+1} \right) \QQ^+ \right\Vert _F \\
%	&=  \left\Vert \vecc \left(\QQ^+ e^{t\QQ} \left( \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \QQ^{k+1}\JJ\QQ^{k+1} \right) \QQ^+ \right) \right\Vert _F \\
%	&= \left\Vert  (\QQ^{+T} \otimes \QQ^+) (\II \otimes e^{t\QQ}) \vecc \left( \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \QQ^{k+1}\JJ\QQ^{k+1} \right)    \right\Vert_F  \\
%	&= \left\Vert  (\QQ^T \otimes \QQ)^+ (\II \otimes e^{t\QQ}) \left( \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \QQ^{T(k+1)} \otimes \QQ^{k+1}  \right)   \vecc(\JJ)  \right\Vert_F  \\
%	&= \left\Vert  (\QQ^T \otimes \QQ)^+ (\II \otimes e^{t\QQ}) \left( \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} (\QQ^{T} \otimes \QQ)^{k+1}  \right)   \vecc(\JJ)  \right\Vert_F  \\
%	&= \left\Vert  (\QQ^T \otimes \QQ)^+ (\II \otimes e^{t\QQ}) \left( \exp(t\QQ^T\otimes \QQ) - t\QQ^T\otimes \QQ - \II \right)   \vecc(\JJ)  \right\Vert_F  \, .
%\end{align*}
%
%\textcolor{red}{\textbf{Where I'm stuck today:}}  I can bound the terms including $\QQ^T\otimes \QQ$ and $\II$, but I can't figure out how to bound 
%\begin{align*}
% (\QQ^T \otimes \QQ)^+ (\II \otimes e^{t\QQ}) \exp(t\QQ^T\otimes \QQ) \, .
%\end{align*}
%In particular, we can write
%\begin{align*}
%	\QQ^T \otimes \QQ &= \MM^{-T} \DD \MM^T \otimes \MM \DD \MM^{-1} \\
%	&=  (\MM^{-T} \otimes \MM)  ((\DD \MM^T) \otimes  (\DD \MM^{-1})) \\
%	&= (\MM^{-T} \otimes \MM)  (\DD  \otimes  \DD) (\MM^{T} \otimes \MM^{-1}) \\
%	&= \GG (\DD  \otimes  \DD) \GG^{-1} 
%\end{align*}
%for $\GG = (\MM^{-T} \otimes \MM)$.  From here, it becomes clear that the term $\exp(t\QQ^T\otimes \QQ)$ is particularly problematic since
%\begin{align*}
%\exp(t\QQ^T\otimes \QQ) &= \GG \exp(t \DD\otimes \DD) \GG^{-1} \\
%&= \GG \exp \begin{pmatrix}
%	 td_1 \DD	& 0 &\dots & & \\
%	0  & td_2 \DD &0  & \dots& \\
%	\vdots &0 & \ddots & \\
%	& \vdots& & td_{S-1} \DD &0 \\
%	&&&0&0
%\end{pmatrix}  \GG^{-1} \, .
%\end{align*}
%This is bad because $d_s\DD$ have positive values and so the exponential explodes as $t\rightarrow \infty$.

\appendix

\section{Loose bounds}\label{sec:loose}

The following loose bounds do not leverage the structure of the CTMC generator matrix $\QQ$.

\subsection{Upper bound 1}



For a submultiplicative matrix norm, we have
\begin{align*}
	\Vert \{\MM_1, \MM_2^k \}  \Vert \leq 2^k \Vert \MM_1\Vert \Vert\MM_2 \Vert ^k \, .
\end{align*}
We use this to obtain our first upper bound on $err_{ij}(\QQ)$:
\begin{align*}
	err_{ij}(\QQ) &= \left\Vert e^{t\QQ}  \sum_{k=1}^\infty \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} \right\Vert  \\
	&\leq \Vert e^{t\QQ} \Vert \sum_{k=1}^\infty \left\Vert \frac{t^{k+1}}{(k+1)!} \{\JJ,\QQ^k\} \right\Vert  \\
	&=  \Vert e^{t\QQ} \Vert \sum_{k=1}^\infty \frac{t}{k+1} \frac{(2t \Vert \QQ \Vert)^k}{k!}\\
	&= \Vert e^{t\QQ} \Vert   \frac{\exp(2t\Vert \QQ \Vert)-2t\Vert\QQ\Vert-1}{2\Vert \QQ \Vert} 
\end{align*}


\subsection{Upper bound 2}

We start with another representation of the derivative \citep{al2009computing}:
\begin{align*}
	\nabla_{\JJ} e^{t\QQ} = \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^k \QQ^{p-1} \JJ \QQ^{k-p} 
\end{align*}
and the fact that
the fact that, for the Frobenius norm $\Vert \cdot \Vert_F$, we have \citep{wu2010short}
\begin{align*}
	\Vert [\MM_1,\MM_2] \Vert_F \leq \sqrt{2} \Vert \MM_1 \Vert_F \Vert \MM_2\Vert_F \, .
\end{align*}
Using these results, the truncation error may be rewritten
\begin{align*}
	err_{ij}(\QQ)  &=\left\Vert - te^{t\QQ} \JJ  +  \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^k \QQ^{p-1} \JJ \QQ^{k-p}\right\Vert_F \\
	&= \left\Vert \sum_{k=1}^\infty \frac{t^k}{k!} \left( \left( \sum_{p=1}^k \QQ^{p-1} \JJ \QQ^{k-p} \right) - k \QQ^{k-1} \JJ \right)  \right\Vert_F\\
	&= \left\Vert \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^k \QQ^{p-1} \JJ \QQ^{k-p}  -  \QQ^{k-1} \JJ \right\Vert_F \\
	&=\left\Vert  \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^{k-1} \QQ^{p-1} \JJ \QQ^{k-p}  -  \QQ^{k-1} \JJ\right\Vert_F \\
	&=\left\Vert  \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^{k-1} \QQ^{p-1}\left( \JJ \QQ^{k-p}  -  \QQ^{k-p} \JJ \right)\right\Vert_F \\
	&= \left\Vert  \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^{k-1} \QQ^{p-1}[\JJ, \QQ^{k-p}] \right\Vert_F  \\
	&\leq  \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^{k-1} \Vert \QQ^{p-1} \Vert_F \Vert[\JJ, \QQ^{k-p}]\Vert_F 
	\leq \sqrt{2}  \sum_{k=1}^\infty \frac{t^k}{k!} \sum_{p=1}^{k-1} \Vert \QQ^{k-1} \Vert_F  \\
	&= \sqrt{2}  \sum_{k=1}^\infty \frac{t^k}{k!} (k-1) \Vert \QQ \Vert_F^{k-1} = \sqrt{2} \frac{e^{t\Vert \QQ\Vert_F}(t\Vert\QQ\Vert_F - 1) + 1}{\Vert \QQ \Vert_F} \, .
\end{align*}


\begin{figure}[!p]
	\centering
	\includegraphics[width=\linewidth]{frobeniusScaling.pdf}
	\caption{Anecdotal (single simulation) error profiles with change in time $t$ and dimension. Errors calculated using Frobenius norm.}\label{fig:frob}
\end{figure}

\begin{figure}[!p]
	\centering
	\includegraphics[width=\linewidth]{infinityScaling.pdf}
	\caption{Anecdotal (single simulation) error profiles with change in time $t$ and dimension. Errors calculated using infinity norm.}\label{fig:inf}
\end{figure}

\bibliographystyle{sysbio}
\bibliography{refs}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
